{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "649c9ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "import cloudpickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a15cbf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/app/examples/iris/serving/\")\n",
    "INPUT_DATA = \"static/data/inputs.csv\"\n",
    "GEN_SIZE = 1000\n",
    "FEATURES = [\"sepal-length\", \"sepal-width\", \"petal-length\", \"petal-width\"]\n",
    "LABEL = \"species\"\n",
    "IRIS_SERVING_URL = \"http://iris_serving:3000\"\n",
    "\n",
    "raw_data = pd.read_csv(INPUT_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa82ca78",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Helper Functions\n",
    "\n",
    "- `load_logreg`: use a logistic-regression model to label the new data\n",
    "- `gen_data_drift`: add white noises (independent Gaussians) to the random draw data from orginal 150 data points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "033b4cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_logreg():\n",
    "    with open(\"logreg.pkl\", \"rb\") as logreg_io:\n",
    "        model = cloudpickle.load(logreg_io)\n",
    "    with open(\"scaler.pkl\", \"rb\") as scaler_io:\n",
    "        scaler = cloudpickle.load(scaler_io)\n",
    "    return scaler, model\n",
    "\n",
    "\n",
    "def gen_data_drift(drift_mean=0.5, drift_std=0.2):\n",
    "    inputs = raw_data[FEATURES]\n",
    "    index = np.random.choice(range(inputs.shape[0]), GEN_SIZE)\n",
    "    inputs = inputs.iloc[index]\n",
    "    noises = np.random.normal(loc=drift_mean, scale=drift_std, size=inputs.shape)\n",
    "    inputs = inputs + noises\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9dcbda",
   "metadata": {},
   "source": [
    "# Request for Inference\n",
    "\n",
    "In this demo, the IRIS ML system is running in restful APIs for real-time inference. A daemon monitoring process is running to monitor the data and performance of inferences.\n",
    "\n",
    "For batch inference application, we can schedule with Airflow DAGs instead of restful API.\n",
    "\n",
    "We will attack the online ML system by injecting purtubed features. \n",
    "\n",
    "In current production configuration:\n",
    "- data monitoring is triggered with every `1,000` new data\n",
    "- performance monitoring is triggered with every `3,000` new data\n",
    "\n",
    "If a data skew is detected, it means that there is high possibility to get model performance distorted. \n",
    "Therefore, performance monitoring is ad-hocly triggered when data skew is detected.\n",
    "If performance score is lower than configured threshold (defined in model evaluation configuration in model bundle), the model retrain pipeline will be triggered\n",
    "\n",
    "Before starting this section, check the model version up for service in:\n",
    "http://localhost:3000/model_ver\n",
    "\n",
    "Check data monitoring reports in:\n",
    "http://localhost:3000/data_reports\n",
    "\n",
    "Check performance monitoring reports in:\n",
    "http://localhost:3000/performance_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134b42b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRIFT_MEAN = [0, 0, 0, 0]\n",
    "# DRIFT_MEAN = [0.5, 0.5, 0.5, 0.5]\n",
    "DRIFT_MEAN = [1, 1, 1, 1]\n",
    "# DRIFT_STD = [0, 0, 0, 0]\n",
    "# DRIFT_STD = [0.3, 0.2, 0.5, 0.5]\n",
    "DRIFT_STD = [0.6, 0.5, 1.0, 1.0]\n",
    "input_data = gen_data_drift(drift_mean=DRIFT_MEAN, drift_std=DRIFT_STD)\n",
    "response = requests.post(\n",
    "    f\"{IRIS_SERVING_URL}/inference\",\n",
    "    json=input_data.to_json(orient=\"split\"),\n",
    "    params={\"prediction_key\": \"classes\"},\n",
    ")\n",
    "response_json = json.loads(response.text)\n",
    "anomaly = response_json[\"Anomaly\"]\n",
    "prediction = response_json[\"classes\"]\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7f0bb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Label data and send back to server\n",
    "\n",
    "Use logistic-regression model to label the data and upload to IRIS server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0997555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label data uploaded.\n"
     ]
    }
   ],
   "source": [
    "scaler, logreg = load_logreg()\n",
    "label_data = input_data.copy()\n",
    "label_data['species'] = logreg.predict(scaler.transform(input_data))\n",
    "response = requests.post(\n",
    "    f\"{IRIS_SERVING_URL}/upload_label_data\",\n",
    "    json=label_data.to_json(orient=\"split\")\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd1f09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
